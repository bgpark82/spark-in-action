{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dropping Column\n",
    "- Dropping column\n",
    "- Dropping rows\n",
    "- Various parameter in dropping functionality\n",
    "- Handling missing values by Mean, Median and Mode"
   ],
   "id": "120cdf8c812aea0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:08:23.087449Z",
     "start_time": "2024-08-11T20:08:23.007468Z"
    }
   },
   "cell_type": "code",
   "source": "from pyspark.sql import SparkSession",
   "id": "c4d5268c0513c755",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:08:58.136604Z",
     "start_time": "2024-08-11T20:08:54.153901Z"
    }
   },
   "cell_type": "code",
   "source": "spark = SparkSession.builder.appName('spark').getOrCreate()",
   "id": "e70dc6809a442e29",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/11 22:08:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/08/11 22:08:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:12:10.081555Z",
     "start_time": "2024-08-11T20:12:04.870740Z"
    }
   },
   "cell_type": "code",
   "source": "df_pyspark = spark.read.csv('test3.csv', header=True, inferSchema=True)",
   "id": "838892335e88d0c0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:12:12.109300Z",
     "start_time": "2024-08-11T20:12:11.760789Z"
    }
   },
   "cell_type": "code",
   "source": "df_pyspark.show()",
   "id": "8b43a75c351a433d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|  31|        10| 30000|\n",
      "| Sunhand|  30|         8| 50000|\n",
      "|   Sunny|  29|         4| 20000|\n",
      "|    Paul|  24|         3| 15000|\n",
      "|Shuhaham|  21|         1| 18000|\n",
      "|  Mahesh|NULL|      NULL| 40000|\n",
      "|    NULL|  34|        10| 38000|\n",
      "|    NULL|  36|      NULL|  NULL|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:12:24.582372Z",
     "start_time": "2024-08-11T20:12:24.579643Z"
    }
   },
   "cell_type": "code",
   "source": "# Drop column",
   "id": "be060c082332d0b8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:12:34.171222Z",
     "start_time": "2024-08-11T20:12:33.790135Z"
    }
   },
   "cell_type": "code",
   "source": "df_pyspark.drop('Name').show()",
   "id": "556bb14b932ce493",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  31|        10| 30000|\n",
      "|  30|         8| 50000|\n",
      "|  29|         4| 20000|\n",
      "|  24|         3| 15000|\n",
      "|  21|         1| 18000|\n",
      "|NULL|      NULL| 40000|\n",
      "|  34|        10| 38000|\n",
      "|  36|      NULL|  NULL|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:13:02.083275Z",
     "start_time": "2024-08-11T20:13:01.894645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# any row with null value will be deleted\n",
    "df_pyspark.na.drop().show()"
   ],
   "id": "5c1417e704089f5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|   Krish| 31|        10| 30000|\n",
      "| Sunhand| 30|         8| 50000|\n",
      "|   Sunny| 29|         4| 20000|\n",
      "|    Paul| 24|         3| 15000|\n",
      "|Shuhaham| 21|         1| 18000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:14:21.546089Z",
     "start_time": "2024-08-11T20:14:21.291413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# any: how = 'all': when all of value in columns are null\n",
    "df_pyspark.na.drop(how='all').show()"
   ],
   "id": "3b387f17d224b14e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|  31|        10| 30000|\n",
      "| Sunhand|  30|         8| 50000|\n",
      "|   Sunny|  29|         4| 20000|\n",
      "|    Paul|  24|         3| 15000|\n",
      "|Shuhaham|  21|         1| 18000|\n",
      "|  Mahesh|NULL|      NULL| 40000|\n",
      "|    NULL|  34|        10| 38000|\n",
      "|    NULL|  36|      NULL|  NULL|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:14:51.769788Z",
     "start_time": "2024-08-11T20:14:51.611377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# any: how = 'all': when all of value in columns are null\n",
    "df_pyspark.na.drop(how='any').show()"
   ],
   "id": "104c6dd9de6b2aaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|   Krish| 31|        10| 30000|\n",
      "| Sunhand| 30|         8| 50000|\n",
      "|   Sunny| 29|         4| 20000|\n",
      "|    Paul| 24|         3| 15000|\n",
      "|Shuhaham| 21|         1| 18000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:16:04.789437Z",
     "start_time": "2024-08-11T20:16:04.502162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# threshold = 2: at least 2 non null value present, it's not deleted\n",
    "df_pyspark.na.drop(how='any', thresh=2).show()"
   ],
   "id": "d216cfc3e69357f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|  31|        10| 30000|\n",
      "| Sunhand|  30|         8| 50000|\n",
      "|   Sunny|  29|         4| 20000|\n",
      "|    Paul|  24|         3| 15000|\n",
      "|Shuhaham|  21|         1| 18000|\n",
      "|  Mahesh|NULL|      NULL| 40000|\n",
      "|    NULL|  34|        10| 38000|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:17:10.788957Z",
     "start_time": "2024-08-11T20:17:10.592966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# threshold = 2: at least 2 non null value present, it's not deleted\n",
    "df_pyspark.na.drop(how='any', thresh=1).show()"
   ],
   "id": "4650ae5016bf0416",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|  31|        10| 30000|\n",
      "| Sunhand|  30|         8| 50000|\n",
      "|   Sunny|  29|         4| 20000|\n",
      "|    Paul|  24|         3| 15000|\n",
      "|Shuhaham|  21|         1| 18000|\n",
      "|  Mahesh|NULL|      NULL| 40000|\n",
      "|    NULL|  34|        10| 38000|\n",
      "|    NULL|  36|      NULL|  NULL|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:19:11.563548Z",
     "start_time": "2024-08-11T20:19:11.367055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# subset\n",
    "df_pyspark.na.drop(how='any', subset=['Experience']).show()"
   ],
   "id": "ec978223b90e9964",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|   Krish| 31|        10| 30000|\n",
      "| Sunhand| 30|         8| 50000|\n",
      "|   Sunny| 29|         4| 20000|\n",
      "|    Paul| 24|         3| 15000|\n",
      "|Shuhaham| 21|         1| 18000|\n",
      "|    NULL| 34|        10| 38000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:19:51.185083Z",
     "start_time": "2024-08-11T20:19:51.182735Z"
    }
   },
   "cell_type": "code",
   "source": "# Filling the missing value",
   "id": "f492beefce406e6a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:21:10.432812Z",
     "start_time": "2024-08-11T20:21:10.246502Z"
    }
   },
   "cell_type": "code",
   "source": "df_pyspark.na.fill(10, ['Experience','Salary']).show()",
   "id": "1ec6527c4b55c716",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|  31|        10| 30000|\n",
      "| Sunhand|  30|         8| 50000|\n",
      "|   Sunny|  29|         4| 20000|\n",
      "|    Paul|  24|         3| 15000|\n",
      "|Shuhaham|  21|         1| 18000|\n",
      "|  Mahesh|NULL|        10| 40000|\n",
      "|    NULL|  34|        10| 38000|\n",
      "|    NULL|  36|        10|    10|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:21:26.362585Z",
     "start_time": "2024-08-11T20:21:26.230408Z"
    }
   },
   "cell_type": "code",
   "source": "df_pyspark.show()",
   "id": "d662a72831c98b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|  31|        10| 30000|\n",
      "| Sunhand|  30|         8| 50000|\n",
      "|   Sunny|  29|         4| 20000|\n",
      "|    Paul|  24|         3| 15000|\n",
      "|Shuhaham|  21|         1| 18000|\n",
      "|  Mahesh|NULL|      NULL| 40000|\n",
      "|    NULL|  34|        10| 38000|\n",
      "|    NULL|  36|      NULL|  NULL|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:24:08.836737Z",
     "start_time": "2024-08-11T20:24:08.831003Z"
    }
   },
   "cell_type": "code",
   "source": "from pyspark.ml.feature import Imputer",
   "id": "941664eedcc47f1b",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:24:29.510666Z",
     "start_time": "2024-08-11T20:24:29.451133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imputer = (Imputer(\n",
    "    inputCols = ['age', 'Experience', 'Salary'],\n",
    "    outputCols= [\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
    ").setStrategy(\"mean\"))\n",
    "    "
   ],
   "id": "ef81f5e116b02f61",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T20:25:06.101114Z",
     "start_time": "2024-08-11T20:25:04.554247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add imputation cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ],
   "id": "5e7197360fe8bf33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "|    Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Krish|  31|        10| 30000|         31|                10|         30000|\n",
      "| Sunhand|  30|         8| 50000|         30|                 8|         50000|\n",
      "|   Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
      "|    Paul|  24|         3| 15000|         24|                 3|         15000|\n",
      "|Shuhaham|  21|         1| 18000|         21|                 1|         18000|\n",
      "|  Mahesh|NULL|      NULL| 40000|         29|                 6|         40000|\n",
      "|    NULL|  34|        10| 38000|         34|                10|         38000|\n",
      "|    NULL|  36|      NULL|  NULL|         36|                 6|         30142|\n",
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "270aef2f3a62b0d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
